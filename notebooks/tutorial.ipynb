{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd845878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importando as bibliotecas necessárias\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, count, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41aca1d1-cbc9-4804-a187-23d5541ef546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Criando a SparkSession apontando para o container do master node (7077)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark Demo\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "499457ba-7a1c-44f9-87c8-856d5f1bcf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplo 1\n",
    "# Criando um dataframe que vai de 0 a 999 e retorna quantos números são pares\n",
    "\n",
    "df = spark.range(1000).toDF(\"number\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d51c77c-4d3f-4157-b79f-0b4cbb8cfd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando transformação para filtrar numéros impares\n",
    "# Note que é apenas um plano de execução. Nenhum resultado é obtido\n",
    "\n",
    "df_pair = df.where(\"number % 2 = 0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c315ed0-e6c1-44a2-b527-0490233161b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [id#0L AS number#2L]\n",
      "+- *(1) Filter ((id#0L % 2) = 0)\n",
      "   +- *(1) Range (0, 1000, step=1, splits=2)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Coloca em operação o plano de execução com a ação count()\n",
    "\n",
    "#df_pair.count()\n",
    "df_pair.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d36e7b4b-34f7-4d28-857d-6d38f62dd20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Voos: string (nullable = true)\n",
      " |-- Companhia.Aerea: string (nullable = true)\n",
      " |-- Codigo.Tipo.Linha: string (nullable = true)\n",
      " |-- Partida.Prevista: timestamp (nullable = true)\n",
      " |-- Partida.Real: string (nullable = true)\n",
      " |-- Chegada.Prevista: timestamp (nullable = true)\n",
      " |-- Chegada.Real: string (nullable = true)\n",
      " |-- Situacao.Voo: string (nullable = true)\n",
      " |-- Codigo.Justificativa: string (nullable = true)\n",
      " |-- Aeroporto.Origem: string (nullable = true)\n",
      " |-- Cidade.Origem: string (nullable = true)\n",
      " |-- Estado.Origem: string (nullable = true)\n",
      " |-- Pais.Origem: string (nullable = true)\n",
      " |-- Aeroporto.Destino: string (nullable = true)\n",
      " |-- Cidade.Destino: string (nullable = true)\n",
      " |-- Estado.Destino: string (nullable = true)\n",
      " |-- Pais.Destino: string (nullable = true)\n",
      " |-- LongDest: double (nullable = true)\n",
      " |-- LatDest: double (nullable = true)\n",
      " |-- LongOrig: double (nullable = true)\n",
      " |-- LatOrig: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exemplo registro de voos Brasil\n",
    "\n",
    "df_br_flights = spark.read.csv(\"datasets/br_flights.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df_br_flights.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abbac739-5138-4ee1-ad81-da838240c98a",
   "metadata": {},
   "source": [
    "\n",
    "df_br_flights.filter(df_br_flights[\"`Cidade.Origem`\"] == \"Porto Alegre\")\\\n",
    "    .groupBy(\"`Companhia.Aerea`\") \\\n",
    "    .agg(count(\"*\").alias(\"total_voos\")) \\\n",
    "    .orderBy(desc(\"total_voos\")) \\\n",
    "    .show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84c0de68-1626-4f39-accc-adde3182c39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COM PREDICATE PUSHDOWN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85470"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicate Pushdown\n",
    "#Ver aba stages e SQL no Spark UI\n",
    "\n",
    "print(\"SEM PREDICATE PUSHDOWN\")\n",
    "df_br_flights_parquet = spark.read.parquet(\"datasets/br_flights.parquet\")\n",
    "df_br_flights_parquet.count()\n",
    "\n",
    "print(\"COM PREDICATE PUSHDOWN\")\n",
    "df_partitioned = spark.read.parquet(\"datasets/br_flights_partitioned\")\n",
    "df_partitioned.filter(df_partitioned[\"Cidade_Origem\"] == \"Porto Alegre\").count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb41a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Encerrando a SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335e015-8b00-4b06-8d4a-8851dd829e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
